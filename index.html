
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Go 2 Class 4 Me</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- Custom styles for this template -->
    <link href="starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <!-- <script src="../../assets/js/ie-emulation-modes-warning.js"></script> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>

          <a class="navbar-brand" href="#">Go 2 Class 4 Me</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="#">Home</a></li>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#obj">Project Objective</a></li>
            <li><a href="#design">Design</a></li>
            <li><a href="#testing">Testing</a></li>
            <li><a href="#result">Result</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">

      <div class="starter-template">
        <h1>ECE 5725 Project : Go2Class4Me Robot</h1>
        <p class="lead">Created by:<br>Christine Ahn (cya6), Sophie He (bh377)</p>
      </div>

      <hr>
      <div class="center-block">
          <iframe width="640" height="360" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allowfullscreen></iframe>
          <h4 style="text-align:center;">Demonstration Video</h4>
      </div>

      <hr id="intro">

      <div style="text-align:center;">
              <h2>Introduction</h2>
              <p style="text-align: left;padding: 0px 30px;">
                One day at Cornell University, two students, Christine and Sophie were wondering what they should do for their final project in their Embedded OS class. While walking to their classes, they realized, "Ah, winter is coming" and there, an idea popped in both of their minds. What if something could go to class in their stead? Instead of walking to class in the cold weather, especially when it starts to snow, we could just virtually be there through a robot? And even better, on days where we are just too tired to get out of bed, this robot could still go to class for us!
                <br><br>
                For any time, whether you are too lazy to get out of bed or the slushy snow outside is too serious of a slipping hazard, here we introduce and propose a wirelessly controlled robot that can go to class for students. While in your bed, all you need to do is open the app, and then move your phone to move the robot!
              </p>
      </div>

    <hr id='obj'>

      <div class="row">
          <div class="col-md-8" style="font-size:18px;">
          <h2>Project Objective:</h2>
          <ul>
              <li>Control the robot wirelessly using a phone.</li>
              <li>See and hear what the robot sees and hears through the phone.</li>
              <li>Feel that one could possibly have the robot go to class for them.</li>
          </ul>
          </div>
      </div>

    <hr id='design'>

      <div style="text-align:center;">
          <h2>Design</h2>
          <br>
          <img class="img-rounded" src="pics/system_diagram.jpg" alt="system diagram" width="541" height="373">
          <p><i>Diagram of the overall system of our project </i></p>
          <br>
          <p style="text-align: left;padding: 0px 30px;">
              Our project consists of a robot that can move forward, backward, turn left, and turn right depending on inputs from a wireless accelerometer on a phone. The robot can also capture audio through a microphone and video imaging using a camera, both configured onto the robot. The image and audio are transmitted to a phone via WiFi.
              <br>
              By the end of our 5 weeks, we have successfully accomplished the following :
            <ul style="text-align: left;padding: 0px 30px;">
              <li>Implemented socket programming for communication between the robot and phone</li>
              <li>Built robot using materials provided in Lab 3</li>
              <li>Configured servos for the robot's motion through PWM signals</li>
              <li>Set up Camera and Microphone and livestreamed it online to a website</li>
              <li>Set up phone's accelerometer information to send to pi</li>
              <li>Created an application for the phone to diplay the livestream video and audio</li>
            </ul>
          </p>
          <br><br>
          <div class="robo_images" style="text-align:center;">
          <img class="img-rounded" src="pics/robot_front.jpg" alt="robot_front" width="240" height="240">
          <img class="img-rounded" src="pics/robot_right.jpg" alt="robot_right" width="240" height="240">
          <img class="img-rounded" src="pics/robot_left.jpg" alt="robot_left" width="240" height="240">
          <img class="img-rounded" src="pics/robot_back.jpg" alt="robot_back" width="240" height="240">
          </div>
      </div>

    <hr id='camera'>

      <div style="text-align:center;">
              <h2>Camera</h2>
              <p style="text-align: left;padding: 0px 30px;">
              	We used the Raspberry Pi camera and installed it following this
                <a href="https://thepihut.com/blogs/raspberry-pi-tutorials/16021420-how-to-install-use-the-raspberry-pi-camera">tutorial</a>.

                We first connected the camera in the slot in the Raspberry Pi,
                which is between the HDMI and Ethernet ports,
                with the silver connectors facing the HDMI port.

                Then we ran <code> sudo raspi-config</code> in the terminal
                to enable the camera. This is achieved by selecting
                <em> 5 Interfacing Options -> P1 Camera -> Yes</em>.

                If the camera option is not available, then an update needs
                to be made, which in this case, <code>sudo apt-get update</code>
                and <code>sudo apt-get upgrade</code> would need to be run in
                the terminal window.

                After enabling the camera,
                we rebooted (<code>sudo reboot</code>)the Raspberry Pi.

                <br><br>

                We played around with the camera by taking photos (<code>raspistill -o image.jpg</code>)
                and videos (<code>raspivid -o video.h264 -t 10000</code>).
                This can be viewed using <code> gpicview image.jpg </code>
                for photos and <code> omxplayer -o hdmi /path/to/filename.mp4 </code>
                for videos.

                <br><br>

                For livestreaming video, we followed the following
                <a href="https://randomnerdtutorials.com/video-streaming-with-raspberry-pi-camera/?fbclid=IwAR2VapDATNAdWZw4prG8uiNBKwqL0IXu7jidJOO81o0FDb9PHFSmfcW6Odc">tutorial</a>
                and used this <a href="https://raw.githubusercontent.com/RuiSantosdotme/Random-Nerd-Tutorials/master/Projects/rpi_camera_surveillance_system.py">code</a>
                to stream the live video feed to a website http://<Your_Pi_IP_Address>:8000.

                We accessed the video streaming through an Android phone that
                is connected to the same WiFi network, enabling the user on the
                phone end to view the live feed of the camera without being in
                the same area as the camera. We were able to get this to work with
                very little latency.

                <br><br>

                <img class="img-rounded" src="pics/camera1.HEIC" alt="testing camera" width="240" height="240">
                <p><i>Camera live feed showing up on phone</i></p>

              </p>
      </div>

      <hr id='audio'>

      <div style="text-align:center;">
              <h2>Audio</h2>
              <p style="text-align: left;padding: 0px 30px;">
             <li>We used this microphone < put info on it here >
             <li>We set up the audio < detail steps on how its done >
             <li>It plays on a website.
             <li>Edited the rpi camera code to put the audio on the website as well.
             <li>Comments: the microphone sucks. Possible improvement is to use an earphone's mic instead.
          </p>
      </div>

      <hr id='androidscreen'>

      <div style="text-align:center;">
          <h2>Android Application</h2>
<br>
          <video id="video" width="640" height="330" autoplay="autoplay" muted="muted">
          <source src="robot_from_phone_view.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video>
          <p>
            <i>Video from the phone's point of view, controlling the robot to make it enter the lab room. </i>
          </p>
<br>
          <p style="text-align: left;padding: 0px 30px;">
            We were able to get the livestream video and audio by using webView on the android phone through this <a href="https://medium.com/@stevesohcot/andriod-studio-webview-tutorial-4651701d7d1a">tutorial</a>. We initially tried to use videoView and vitamio but could not get that to work.
            <br><br>
            As in the tutorial, we initialized a WebView variable and set it up in the onCreate section as such :
          </p>
          <div align="left">
            <pre><code>
      public class MainActivity extends AppCompatActivity implements SensorEventListener {
        private WebView webview ;
        ...
        @Override
        protected void onCreate (Bundle savedInstanceState) {
        ...
        webview =(WebView)findViewById(R.id.webView);

        webview.setWebViewClient(new WebViewClient());
        webview.getSettings().setJavaScriptEnabled(true);
        webview.getSettings().setDomStorageEnabled(true);
        webview.setOverScrollMode(WebView.OVER_SCROLL_NEVER);
        webview.loadUrl(videoURL);

       }
      }
            </code></pre>
          </div>
          <p style="text-align: left;padding: 0px 30px;">
            Then, in the activity_main.xml file (under the res/layouts folder), one must also remember to put in a WebView object so that the findViewById" line can find the view and load the website onto that view.
            <br><br>
          </p>
          <h4 style="text-align: left;padding: 0px 30px;">Bugs</h4>
          <p style="text-align: left;padding: 0px 30px;">
            If the phone still cannot access the website, one should check their AndroidManifext.xml file (under the manifests folder) if it has the
            <b>&lt;uses-permission android:name="android.permission.INTERNET"/&gt;</b> line included. We also found a bug where the phone could not access the website if it was not under the same Cornell Wifi as the robot. So, one should make sure that if the Pi is livestreaming the camera and audio information online under the Cornell Wifi that the phone is also using the Cornell Wifi (not data).
          </p>

      </div>

      <hr id='control'>

      <div style="text-align:center;">
              <h2>Controlling the Robot with a Phone</h2>
              <div class="col-md-4" style="text-align:center;">
              <img class="img-rounded" src="pics/accelerometer.png" alt="Phone coordinate system for sensors" width="240" height="240">
              </div>
              <br>
              <p style="text-align: left;padding: 0px 30px;">
              To control the robot wirelessly, we needed to create a socket to send accelerometer information from the phone (the server) to be received by the Raspberry Pi (the client). All code can be either seen in the Code Appendix section or on the <a href="https://github.com/cya6/WifiRobot">GitHub repository</a>.
              </p>
              <h3>1. Configuring the Phone's Accelerometer </h3>
              <p style="text-align: left;padding: 0px 30px;">
                We configured the phone's accelerometer using AndroidStudio to create an application.
                To configure and use the accelerometer within the phone through the app, we followed some tutorials that showed us how to set up and print out the accelerometer values:
                <br><br>
                <a href="https://www.youtube.com/watch?v=pkT7DU1Yo9Q&t=682s">Set up accelerometer</a>
                <br>
                <a href="https://www.youtube.com/watch?v=Rda_5s4rObQ">Print out accelerometer values</a>
                <br><br>

                First, we used an empty template through Android Studio. Then, we followed the tutorial, adding the SensorManager and Sensor variables to the MainActivity class. Next, inside the onCreate function, we configure the SensorManager and Sensor to get information from the phone's accelerometer. Although the tutorial uses the standard default accelerometer, we chose to use the rotation vector accelerometer as it seemed more able to sense turning the phone more easily. An overview of the available sensors on the phone can be seen <a href="https://developer.android.com/guide/topics/sensors/sensors_motion.html">here</a>.
                <br><br>
                We also then configure the SensorManager to allow us listen to the information from the phone's accelerometer. Next, by using the sensor class, there are two functions that must be included in the MainActivity file : onAccuracyChanged and onSensorChanged. For our purposes, we only use onSensorChanged since we only wanted to read the x, y, and z values output by the accelerometer. In the onSensorChanged function, it takes in a sensor event which then contains the x, y, and z values from the sensor. We then save this information by saving the read values to a string.
                <br>
              </p>
                <div align = "left">
                <pre><code>
public class MainActivity extends AppCompatActivity implements SensorEventListener {

    private static final String TAG = "MainActivity";
    private SensorManager sensorManager;
    private Sensor accelerometer;

    String x,y,z;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        sensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE);
        accelerometer = sensorManager.getDefaultSensor(Sensor.TYPE_ROTATION_VECTOR);

        sensorManager.registerListener(MainActivity.this,accelerometer, SensorManager.SENSOR_DELAY_NORMAL);
    }


    @Override
    public void onAccuracyChanged(Sensor sensor, int accuracy) {

    }

    @Override
    public void onSensorChanged(SensorEvent event) {
        Log.d(TAG, "X: " + event.values[0] + " |Y: " + event.values[1]);

        x = "xValue: "+event.values[0];
        y = "yValue: "+event.values[1];
        z = "zValue: "+event.values[2];

    }
                </code></pre>
              </div>
              <p style="text-align: left;padding: 0px 30px;">
                To see the accelerometer values for yourself, you can use Log.d to print out the values to Android Studio's Logcat. Next, after setting up the accelerometer on the phone, we needed to send it to the RPi.
              </p>
              <h3>2. Sending information to the RPi with Socket Programming </h3>

              <h4 style="text-align: left; padding: 0px 30px">Server side ( Android Application )</h4>
              <p style="text-align: left;padding: 0px 30px;">
                We used socket programming to send information from the phone to the RPi. The phone was set up as the server by following the information <a href="http://androidsrc.net/android-client-server-using-sockets-server-implementation/">here</a>.
                <br><br>
                Following this tutorial, after setting up the server as they did, we changed some parts of it to send to the client the accelerometer information continuously. In MainActivity.java, we initialize the server in onCreate. We also include a function that will destroy the server when the application is closed.
                <div align="left">
                  <pre><code>
        public class MainActivity extends AppCompatActivity implements SensorEventListener {
          Server server ;
          ...

          @Override
          protected void onCreate(Bundle savedInstanceState) {
            ...
            server = newServer(this);
            ...
          }
          ...

          @Override
          protected void onDestroy() {
              super.onDestroy();
              server.onDestroy();
          }
        }
                  </code></pre>
                </div> <p>
              <p style="text-align: left;padding: 0px 30px;">
                In Server.java, in the run () code section, we see that it has an outputStream that it sends to the Client, in our case the RPi. We change the section to continuously in a while ( true ) loop, print to the outputStream the x, y, and z values recorded in MainActivity. With this, the server has been set up to send across the accelerometer information. We also modified the tutorial code to not print out anything on the application screen.
              </p>
              <div align="left">
                <pre><code>
        @Override
        public void run() {
            OutputStream outputStream ;

            try {
                outputStream = hostThreadSocket.getOutputStream();
                PrintStream printStream = new PrintStream(outputStream);
                while (true) {
                    printStream.println(activity.x + "\n" +
                            activity.y + "\n" +
                            activity.z  + "\n");
                    sleep(1000);
                }
                printStream.close();

            }
            catch (IOException e) {
                e.printStackTrace();
                message += "Something wrong! " + e.toString() + "\n";
            }
            catch (InterruptedException e) {
                e.printStackTrace();
                message += "Something wrong! " + e.toString() + "\n";
            }

            activity.runOnUiThread(new Runnable() {
                @Override
                public void run() {
                    activity.msg.setText(message);
                }
            });
        }
                </code></pre>
              </div>
              <br>
              <h4 style="text-align: left; padding: 0px 30px">Client side ( from the RPi point of view )</h4>
              <p style="text-align: left;padding: 0px 30px;">
                To set up the client code on the Raspberry Pi, we followed the "Echo Client" code in this <a href="https://realpython.com/python-sockets/">tutorial</a>.
                <br>
                The HOST value was set to the IP address of the android phone ( which can be found by clicking on the wifi button on your phone ).
                We also made sure it was using the same port as was used on the application side in Server.java. A change we made however was to continuously receive data, decode it into ASCII characters, and then send that information to a FIFO. This FIFO is important as it is what we will use to control the robot with the accelerometer. The code can be seen in our <a href="https://github.com/cya6/WifiRobot">repository</a> under client.py.
              </p>

              <h3>3. Moving the robot with the accelerometer information</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Finally, to move the robot, we read from the FIFO and based on the values from the accelerometer, decide to turn left, right, forward, or backwards. Code for this is found in our repository, under <a href="https://github.com/cya6/WifiRobot/blob/master/project/robot_control.py">robot_control.py</a>.
                <br><br>
                To allow the user to stand in any direction and start moving the robot, we first allow for a calibration period in the beginning where it will set the x and z values read to be the setting for which the user wishes to keep the robot still.
                <br>
                Next, after it is calibrated, it continues to read lines from the FIFO. We realized that when the phone (set horizontally) is tilted forward, the z value goes up by 0.1 and x value down by 0.1 from its steady state. To prevent from false forwards however, we set the code up so that it must detect this at least twice before it goes forward. Similarly, to go backwards, it detects that the z value goes down by 0.1 and x value up by 0.1 from its steady state. These threshold values were decided on after trial and error and may need to be adjusted if used on another device.
                We also use a buffer here before we actually decide to move the robot backwards. If neither of these conditions are detected, we keep the robot still.
                <br> <br>
                To go left or right, we depend solely on the x values read from the accelerometer. We also prevent the robot from turning if the user is going forward or backwards at that moment. To go right, we see if the x value goes down by 0.1 and to go left, if it goes up by 0.05. Similarly, this values were also found through trial and error and may need to be adjusted if run on another device. We also use a buffer here to detect more than 2 lefts or rights before the robot will actually turn right or left. If neither are detected, it will remain still.
                <br>

              </p>
      </div>

    <hr id='testing'>

      <div style="text-align:center;">
              <h2>Testing</h2>
              <p style="text-align: left;padding: 0px 30px;">
                We tested our camera's configuration by first taking some sample still pictures. Similarly, we tested the audio's configuration by recording some short snippets using the tutorial.<br>
                We tested the livestream of the camera and audio by going on the website and checking if the latency between the moving on the camera and seeing it on the website was ok. The camera latency was pretty good but the audio latency was slow ( varied from 3 seconds to 20 seconds ). <br>
                We tested the phone application by running it on the phone and seeing that we could see the camera and audio output well, similar to how we saw it on the desktop website. </p>
                <img class="img-rounded" src="pics/testing_camera.jpg" alt="camera view on phone" width="350" height="480">
                <p><i>Testing the camera's view on the phone</i></p>
              <p style="text-align: left;padding: 0px 30px;">
                We tested moving the robot by running the code, and using the application on the phone to move it forward, backward, right, and left. <br>
              </p>

              <img class="img-rounded" src="pics/testing_system.jpg" alt="testing entire process" width="350" height="480">
              <p><i>Testing the wheel movement with the camera</i></p>

          <video id="video" width="640" height="330" autoplay="autoplay" controls>
          <source src="testing_move.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video>
          <p><i>Moving the robot with the phone</i></p>
      </div>

    <hr id='result'>

      <div style="text-align:center;">
              <h2>Result</h2>
              <p style="text-align: left;padding: 0px 30px;">
                final res
              </p>
      </div>

    <hr>

    <div class="row" style="text-align:center;">
          <h2>Work Distribution</h2>
          <div style="text-align:center;">
              <img class="img-rounded" src="pics/group.jpg" alt="Generic placeholder image" style="width:80%;">
              <h4>Project group picture</h4>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/a.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Christine</h3>
              <p class="lead">cya6@cornell.edu</p>
              <p>Worked on the robot.
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/b.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Sophie</h3>
              <p class="lead">bh377@cornell.edu</p>
              <p>Hugged christine
          </div>
      </div>

    <hr>
      <div style="font-size:18px">
          <h2>Parts List</h2>
          <ul>
              <li><a href="https://www.amazon.com/Raspberry-Pi-Camera-Module-Megapixel/dp/B01ER2SKFS">Raspberry Pi Camera V2 $25.00</a></li>
              <li><a href="https://www.amazon.com/eBerry-Microphone-Adjustable-Compatible-Recording/dp/B00UZY2YQE">Microphone $8</a></li>
              <li>Phone - Used student's existing android phone </li>
              <li>Raspberry Pi, LEDs, Resistors, Wires, Robot Parts- Provided in lab</li>
          </ul>
          <h3>Total: $33</h3>
      </div>
      <hr>
      <div style="font-size:18px">
          <h2>References</h2>
          <a href="https://picamera.readthedocs.io/">PiCamera Document</a><br>
          <a href="https://www.youtube.com/watch?v=pkT7DU1Yo9Q&t=682s">Accelerometer Tutorial 1
          </a><br>
          <a href="https://www.youtube.com/watch?v=Rda_5s4rObQ">Accelerometer Tutorial 2
          </a><br>
          <a href="https://developer.android.com/guide/topics/sensors/sensors_motion.html"> Android Sensor Information
          </a><br>
          <a href="http://androidsrc.net/android-client-server-using-sockets-server-implementation/"> Android Socket Programming
          </a><br>
          <a href="https://realpython.com/python-sockets/"> Python Socket Programming
          </a><br>
          <a href="https://medium.com/@stevesohcot/andriod-studio-webview-tutorial-4651701d7d1a"> WebView on Android Phone</a><br>


      </div>

    <hr>

      <div class="row">
              <h2>Code Appendix</h2>
              <h3><a href="https://github.com/cya6/WifiRobot/blob/master/project/robot_control.py">Robot Control Code</a> </h3>
              <h3><a href="https://github.com/cya6/WifiRobot/blob/master/project/client.py">Client Code</a> </h3>
              <h3><a href="https://github.com/cya6/WifiRobot/blob/master/project/rpi_camera.py">Camera Code</a> </h3>
              <h3><a href="https://github.com/cya6/WifiRobot/blob/master/project/rpi_camera.py">Phone Application Code</a> </h3>
              <h3><a href="https://raw.githubusercontent.com/RuiSantosdotme/Random-Nerd-Tutorials/master/Projects/rpi_camera_surveillance_system.py">Camera Web Streaming Code</a> </h3>

      </div>

    </div><!-- /.container -->




    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script> -->
  </body>
</html>
